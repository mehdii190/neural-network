{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsjAuFD0226O1UfEhjlxZm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdii190/neural-network/blob/main/src/variational_AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "A1QB_a-7sMYz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Zzi5KYF8tf3c"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "T3ihABJMtvS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46fb3e30-0a5b-49fc-c739-f2baac319f01"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 28 * 28\n",
        "hidden_dim = 400\n",
        "latent_dim = 20\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root = \"/data\",\n",
        "                                           train = True,\n",
        "                                           transform = transforms.ToTensor(),\n",
        "                                           download = True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root = \"/data\",\n",
        "                                           train = False,\n",
        "                                           transform = transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size =batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                           batch_size =batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "\n",
        "sample_dir = \"results\"\n",
        "if not os.path.exists(sample_dir):\n",
        "  os.makedirs(sample_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "byW39EPLt-8o"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vae model\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VAE,self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(image_size, hidden_dim)\n",
        "    self.fc2_mean = nn.Linear(hidden_dim, latent_dim)\n",
        "    self.fc2_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "    self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
        "    self.fc4 = nn.Linear(hidden_dim, image_size)\n",
        "\n",
        "  def encode(self, x):\n",
        "    h = F.relu(self.fc1(x))\n",
        "    mu = self.fc2_mean(h)\n",
        "    log_var = self.fc2_logvar(h)\n",
        "    return mu , log_var\n",
        "  \n",
        "  def reparameterize(self, mu , logvar):\n",
        "    std = torch.exp(logvar/2)\n",
        "    eps = torch.randn_like(std)\n",
        "    return mu + eps * std\n",
        "\n",
        "  def decode(self, z):\n",
        "    h = F.relu(self.fc3(z))\n",
        "    out = torch.sigmoid(self.fc4(h))\n",
        "    return out\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # x : (batch size , 1,28,28) ==> (batch size, 784)\n",
        "\n",
        "    mu ,logvar= self.encode(x.view(-1,image_size))\n",
        "    z = self.reparameterize(mu, logvar)\n",
        "    recon = self.decode(z)\n",
        "    return  recon , mu , logvar\n",
        "\n",
        "\n",
        "\n",
        "model = VAE().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ekccnwsvwoi2"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_NrT-AinQJk",
        "outputId": "e5ab5b0b-6e18-4a05-f5c8-7925849e5436"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VAE(\n",
              "  (fc1): Linear(in_features=784, out_features=400, bias=True)\n",
              "  (fc2_mean): Linear(in_features=400, out_features=20, bias=True)\n",
              "  (fc2_logvar): Linear(in_features=400, out_features=20, bias=True)\n",
              "  (fc3): Linear(in_features=20, out_features=400, bias=True)\n",
              "  (fc4): Linear(in_features=400, out_features=784, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import open_code\n",
        "def loss_function(recon_image,original_image, mu, logvar):\n",
        "  bce = F.binary_cross_entropy(recon_image,original_image.view(-1,784),reduction=\"sum\")\n",
        "\n",
        "  k1d = 0.5 * torch.sum(logvar.exp()+ mu.pow(2) - 1 - logvar)\n",
        "\n",
        "  #####################\n",
        "\n",
        "  # logvar , exp = (batch size , 20)\n",
        "\n",
        "  #k1d = 0.5 * torch.sum(logvar.epx()+ mu.pow(2) - 1 - logvar, 1)\n",
        "  #k1d_sum = torch.sum(k1d)\n",
        "\n",
        "  #####################\n",
        "\n",
        "\n",
        "  return bce + k1d\n",
        "\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "\n",
        "  train_loss = 0\n",
        "\n",
        "  for i , (image,_) in enumerate(train_loader):\n",
        "    images = image.to(device)\n",
        "    reconstructed , mu , logvar = model(images)\n",
        "    loss = loss_function(reconstructed, images , mu , logvar)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    train_loss += loss.item()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "\n",
        "      print(\"train epoch {} [batch {}/{}]\\tLoss: {:.3f}\".format(epoch , i, len(train_loader),loss.item()/len(images)))\n",
        "\n",
        "  print(\"===> epoch {},average loss: {:.3f}\".format(epoch, train_loss/len(train_loader.dataset)))\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for batch_idx , (image,_) in enumerate(test_loader):\n",
        "      images = image.to(device)\n",
        "      reconstructed , mu , logvar = model(images)\n",
        "      test_loss += loss_function(reconstructed, images , mu , logvar).item()\n",
        "      if batch_idx == 0:\n",
        "        comparison = torch.cat([images[:5],reconstructed.view(batch_size, 1,28,28)[:5]])\n",
        "        save_image(comparison.cpu(), \"results/reconstructed_\"+ str(epoch)+ \".png\",nrow=5)\n",
        "\n",
        "\n",
        "  print(\"===> average test loss: {:.3f}\".format(test_loss/len(test_loader.dataset)))\n",
        "\n"
      ],
      "metadata": {
        "id": "WOUI499Fnu8X"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs+ 1):\n",
        "  train(epoch)\n",
        "  test(epoch)\n",
        "  with torch.no_grad():\n",
        "    sample = torch.randn(64,20).to(device)\n",
        "    gemerated = model.decode(sample).cpu()\n",
        "    save_image(gemerated.view(64,1,28,28),\"results/sample_\"+str(epoch)+\".png\")\n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X19NTDzmr0m_",
        "outputId": "32988487-7946-4372-fc11-2d1b5110a968"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train epoch 1 [batch 0/469]\tLoss: 550.191\n",
            "train epoch 1 [batch 100/469]\tLoss: 185.624\n",
            "train epoch 1 [batch 200/469]\tLoss: 150.844\n",
            "train epoch 1 [batch 300/469]\tLoss: 145.409\n",
            "train epoch 1 [batch 400/469]\tLoss: 130.062\n",
            "===> epoch 1,average loss: 165.522\n",
            "===> average test loss: 128.183\n",
            "train epoch 2 [batch 0/469]\tLoss: 134.439\n",
            "train epoch 2 [batch 100/469]\tLoss: 126.160\n",
            "train epoch 2 [batch 200/469]\tLoss: 122.253\n",
            "train epoch 2 [batch 300/469]\tLoss: 116.506\n",
            "train epoch 2 [batch 400/469]\tLoss: 115.767\n",
            "===> epoch 2,average loss: 121.902\n",
            "===> average test loss: 115.973\n",
            "train epoch 3 [batch 0/469]\tLoss: 119.924\n",
            "train epoch 3 [batch 100/469]\tLoss: 114.270\n",
            "train epoch 3 [batch 200/469]\tLoss: 114.323\n",
            "train epoch 3 [batch 300/469]\tLoss: 113.444\n",
            "train epoch 3 [batch 400/469]\tLoss: 117.549\n",
            "===> epoch 3,average loss: 114.617\n",
            "===> average test loss: 111.716\n",
            "train epoch 4 [batch 0/469]\tLoss: 114.400\n",
            "train epoch 4 [batch 100/469]\tLoss: 112.786\n",
            "train epoch 4 [batch 200/469]\tLoss: 108.591\n",
            "train epoch 4 [batch 300/469]\tLoss: 109.320\n",
            "train epoch 4 [batch 400/469]\tLoss: 113.358\n",
            "===> epoch 4,average loss: 111.580\n",
            "===> average test loss: 110.143\n",
            "train epoch 5 [batch 0/469]\tLoss: 107.181\n",
            "train epoch 5 [batch 100/469]\tLoss: 112.344\n",
            "train epoch 5 [batch 200/469]\tLoss: 105.192\n",
            "train epoch 5 [batch 300/469]\tLoss: 112.069\n",
            "train epoch 5 [batch 400/469]\tLoss: 111.141\n",
            "===> epoch 5,average loss: 109.830\n",
            "===> average test loss: 108.589\n",
            "train epoch 6 [batch 0/469]\tLoss: 107.433\n",
            "train epoch 6 [batch 100/469]\tLoss: 111.174\n",
            "train epoch 6 [batch 200/469]\tLoss: 107.319\n",
            "train epoch 6 [batch 300/469]\tLoss: 108.441\n",
            "train epoch 6 [batch 400/469]\tLoss: 109.773\n",
            "===> epoch 6,average loss: 108.678\n",
            "===> average test loss: 107.666\n",
            "train epoch 7 [batch 0/469]\tLoss: 110.666\n",
            "train epoch 7 [batch 100/469]\tLoss: 110.226\n",
            "train epoch 7 [batch 200/469]\tLoss: 107.314\n",
            "train epoch 7 [batch 300/469]\tLoss: 106.507\n",
            "train epoch 7 [batch 400/469]\tLoss: 106.344\n",
            "===> epoch 7,average loss: 107.832\n",
            "===> average test loss: 107.099\n",
            "train epoch 8 [batch 0/469]\tLoss: 107.579\n",
            "train epoch 8 [batch 100/469]\tLoss: 106.251\n",
            "train epoch 8 [batch 200/469]\tLoss: 107.849\n",
            "train epoch 8 [batch 300/469]\tLoss: 106.249\n",
            "train epoch 8 [batch 400/469]\tLoss: 107.424\n",
            "===> epoch 8,average loss: 107.214\n",
            "===> average test loss: 106.348\n",
            "train epoch 9 [batch 0/469]\tLoss: 104.453\n",
            "train epoch 9 [batch 100/469]\tLoss: 102.853\n",
            "train epoch 9 [batch 200/469]\tLoss: 107.886\n",
            "train epoch 9 [batch 300/469]\tLoss: 105.461\n",
            "train epoch 9 [batch 400/469]\tLoss: 102.261\n",
            "===> epoch 9,average loss: 106.681\n",
            "===> average test loss: 105.956\n",
            "train epoch 10 [batch 0/469]\tLoss: 106.883\n",
            "train epoch 10 [batch 100/469]\tLoss: 101.361\n",
            "train epoch 10 [batch 200/469]\tLoss: 111.487\n",
            "train epoch 10 [batch 300/469]\tLoss: 112.352\n",
            "train epoch 10 [batch 400/469]\tLoss: 105.664\n",
            "===> epoch 10,average loss: 106.240\n",
            "===> average test loss: 105.755\n"
          ]
        }
      ]
    }
  ]
}